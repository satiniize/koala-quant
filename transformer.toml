[model]
vocab_size = 1000    # Add this line
input_dim = 1
d_model = 64
num_heads = 8
num_layers = 4
d_ff = 128
max_seq_length = 128
dropout = 0.2

[training]
batch_size = 32
num_epochs = 200
learning_rate = 0.001
lr_scheduler_step = 10
lr_scheduler_gamma = 0.95
criterion = "CrossEntropyLoss"
optimizer = "Adam"
best_model_path = "best_model.pth"
final_model_path = "final_model.pth"
validation_split = 0.2
checkpoint_frequency = 10
early_stopping_patience = 10
early_stopping_metric = "val_loss"

[checkpointing]
enable_checkpoints = true
checkpoint_dir = "checkpoints"
checkpoint_frequency = 10
keep_last_n = 5

[data]
period = "5y"
training_tickers = [
	# Banking (80%)
	"BBRI.JK",
	"BMRI.JK",
	"BBNI.JK",
	# Consumer Goods (80%)
	"UNVR.JK",
	"INDF.JK",
	"ICBP.JK",
	"HMSP.JK",
	# Infrastructure & Transport (80%)
	"PGAS.JK",
	"JSMR.JK",
	# Manufacturing (80%)
	"ASII.JK",
	# Mining & Resources (80%)
	"ANTM.JK",
	"PTBA.JK",
]
validation_tickers = [
	# Banking (20%)
	"BBCA.JK",
	# Consumer Goods (20%)
	"KLBF.JK",
	# Infrastructure & Transport (20%)
	"TLKM.JK",
	# Manufacturing (20%)
	"SMGR.JK",
	# Mining & Resources (20%)
	"ADRO.JK",
]
sequence_length = 30
train_test_split = 0.8
features = "Close"

[attention]
hidden_size = 64
num_heads = 8
dropout = 0.2

[prediction]
ticker_symbol = "BMRI.JK"
future_days = 64
